<!DOCTYPE HTML>
<html>
    <head>
        <title>Xinghao Zhu</title>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=1000">
        <link rel="stylesheet" href="https://use.typekit.net/quv7bsd.css"> <!-- fonts -->
        <link rel="stylesheet" href="./style.css" />
        <link rel="icon" type="image/x-icon" href="./images/people/favicon.png">

        <!-- <script>
             (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
             (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
             m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
             })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
             ga('create', 'UA-XXXXX-Y', 'auto');
             ga('send', 'pageview');
       </script> -->
    </head>
    
    <body id="body">
        <div id="main"> 

            <!-------------------------------------------------------------------------->
            <!-------------------------------Head--------------------------------------->
            <!-------------------------------------------------------------------------->
            <div id="profile">
              <div id="profile-pic">
                  <img src="images/people/xinghao.png">
                  <p>
                    
                    <a href="https://scholar.google.com/citations?user=vQadVosAAAAJ&hl=en&oi=ao">Google Scholar</a>
                      <!-- FIXME(remove after visa) &nbsp;&nbsp;/&nbsp;&nbsp; -->
                      <!-- FIXME(remove after visa) <a href="./files/CV.pdf">CV</a> -->
                  </p>
              </div>
              <div id="profile-intro">
                  <div id="profile-name">Xinghao Zhu</div>
                  <p>
                      Hi there! I'm a research scientist and a roboticist at the <a href="https://rai-inst.com/"> Robotics and AI Institute </a>(formerly Boston Dynamics AI Institute).
                      <!-- FIXME(remove after visa) I'm interested in enabling robots to interact with the world intelligently and dexterously through learning and control. -->
                      I earned my Ph.D. from the <a href="https://www.berkeley.edu/"> University of California, Berkeley</a>, where I was advised by <a href="https://me.berkeley.edu/people/masayoshi-tomizuka/"> Prof. Masayoshi Tomizuka</a>, a distinguished member of the <a href="https://www.nae.edu/270224/National-Academy-of-Engineering-Elects-111-Members-and-22-International-Members"> National Academy of Engineering</a>.
                      Earlier, I received my Bachelor's degree from the Honors Youth Program at Xi'an Jiaotong University.
                      <br> <br>
                      Email: xizhu [at] theaiinstitute [dot] com <br>
                      

                  </p>
              </div>
              <div style="clear: both;"></div>
          </div>
            
            <!-------------------------------------------------------------------------->
            <!---------------------------Sliding Bar------------------------------------>
            <!-------------------------------------------------------------------------->
            <!-- <div class="section recent-work">
                <div class="slider">
                  <a href="https://sites.google.com/view/diff-lfd"><img src="./images/projects/difflfd.gif"></a>
                  <a href="index.html"><img src="./images/projects/tooluse.gif"></a>
                  <a href="https://ieeexplore.ieee.org/document/9811685"><img src="./images/projects/mlgsl.gif"></a>
                  <a href="index.html"><img src="./images/projects/assembly.gif"></a>
                  <a href="https://ieeexplore.ieee.org/document/8967560"><img src="./images/projects/ppojpo.gif"></a>
                  <a href="https://sites.google.com/view/human-oriented-robot-learning"><img src="./images/projects/humanoid.gif"></a>
                  <a href="https://ieeexplore.ieee.org/document/10160649"><img src="./images/projects/allowcontact.gif"></a>
                  <a href="https://robotics-transformer-x.github.io/"><img src="./images/projects/rtx.gif"></a>
                </div>
            </div> -->

            <div class="divider"></div>
            <div class="section">
                <h1>News</h1>
                <p>
                    <ul>
                      <li> 2025/05 &nbsp;&nbsp;&bull;&nbsp;&nbsp; We are organizing the <a href="https://wbcdcompetition.github.io/"> WBCD challenge</a> at ICRA 2025. </li>
                      <!-- FIXME(remove after visa) <li> 2024/08 &nbsp;&nbsp;&bull;&nbsp;&nbsp; My work on versatile loco-manipulation was featured in Marc Raibertâ€™s keynote at <a href="https://www.wfeo.org/events/world-robot-conference-2024/"> WRC 2024</a>. </li> -->
                      <li> 2024/05 &nbsp;&nbsp;&bull;&nbsp;&nbsp; Two papers accepted by IROS 2024. </li>
                      <li> 2024/05 &nbsp;&nbsp;&bull;&nbsp;&nbsp; Our <a href="https://robotics-transformer-x.github.io/"> Open X-Embodiment</a> project received <strong>Best Paper Award</strong> at ICRA 2024. </li>
                      <li> 2024/05 &nbsp;&nbsp;&bull;&nbsp;&nbsp; Four papers accepted by ICRA 2024. </li>
                      <li> 2024/05 &nbsp;&nbsp;&bull;&nbsp;&nbsp; One paper accepted by RSS 2024. </li>
                      <li> 2024/03 &nbsp;&nbsp;&bull;&nbsp;&nbsp; I joined <a href="https://rai-inst.com/"> The Robotics and AI Institute </a> as a research scientist. </li>
                      <li> 2023/12 &nbsp;&nbsp;&bull;&nbsp;&nbsp; Our LLM-POP received <a href="https://an-instructive-workshop.github.io/#paper-awards"> Honorable Mention</a> at the Instruction Workshop at NeurIPS 2023.  </li>
                      <li> 2023/09 &nbsp;&nbsp;&bull;&nbsp;&nbsp; Our <a href="https://sites.google.com/view/diff-lfd"> Diff-LfD</a> was accepted by CoRL 2023 as Oral. </li>
                      <!-- FIXME(remove after visa) <li> 2022/11 &nbsp;&nbsp;&bull;&nbsp;&nbsp; I delivered a faculty talk at <a href="https://bars2022.github.io/"> BARS </a> representing Prof. Tomizuka. </li> -->
                    </ul>
                </p>
                <div style="clear: both;"></div>
            </div>
            
            <!-------------------------------------------------------------------------->
            <!------------------------Research Projects--------------------------------->
            <!-------------------------------------------------------------------------->
            <div class="divider"></div>
            <div class="section research">
                <h1>Publications</h1>

                <!-- <h3><div id="repBtn"><a href="javascript:showRep()">Representative</a></div>&nbsp;&nbsp;&nbsp;&bull;&nbsp;&nbsp;&nbsp;<div id="showAllBtn"><a href="javascript:hideRep()">See All Publications</a></div></h3> -->
                
                <!-- <div class="research-proj">
                  <a href="XXXXX" class="research-thumb"><img src="images/projects/XXXXX.png" alt="" /></a>
                  <a href="XXXXX" class="research-proj-title">TITLE</a>
                  <p>
                    Authors <br>
                    Publisher <br>
                    <a href="XXXXX">Webpage</a>
                    &nbsp;&bull;&nbsp;
                    <a href="XXXXX">Code</a>
                    &nbsp;&bull;&nbsp;
                    <a href="XXXXX">Paper</a>
                  </p>
                </div> -->
                
                <div class="research-proj">
                  <a href="https://relic-locoman.github.io/" class="research-thumb"><img src="images/projects/relic.gif" alt="" /></a>
                  <a href="https://relic-locoman.github.io/" class="research-proj-title">Versatile Loco-Manipulation through Flexible Interlimb Coordination</a>
                  <p>
                    Xinghao Zhu, Yuxin Chen, Lingfeng Sun, Farzad Niroui, Simon Le Cleac'h, Jiuguang Wang, Kuan Fang <br>
                    Under review <br>
                    <a href="https://relic-locoman.github.io/">Webpage</a>
                    &nbsp;&bull;&nbsp;
                    <a href="https://www.arxiv.org/abs/2506.07876">Paper</a>
                  </p>
                </div>

                <div class="research-proj">
                  <a href="https://sites.google.com/berkeley.edu/efficient-locomotion" class="research-thumb"><img src="images/projects/efficient-locomotion.gif" alt="" /></a>
                  <a href="https://sites.google.com/berkeley.edu/efficient-locomotion" class="research-proj-title">Adaptive energy regularization for autonomous gait transition and energy-efficient quadruped locomotion</a>
                  <p>
                    Xinghao Zhu, Boyuan Liang, Lingfeng Sun, Bike Zhang, Ziyin Xiong, Yixiao Wang, Chenran Li, Koushil Sreenath, Masayoshi Tomizuka <br>
                    ICRA 2025
                    &nbsp;&bull;&nbsp;
                    <a href="https://sites.google.com/berkeley.edu/efficient-locomotion">Webpage</a>
                    &nbsp;&bull;&nbsp;
                    <a href="https://arxiv.org/abs/2403.20001">Paper</a>
                  </p>
                </div>

                <div class="research-proj">
                  <a href="https://glide-manip.github.io/" class="research-thumb"><img src="images/projects/glide.gif" alt="" /></a>
                  <a href="https://glide-manip.github.io/" class="research-proj-title">Planning-Guided Diffusion Policy Learning for Generalizable Contact-Rich Bimanual Manipulation</a>
                  <p>
                    Xuanlin Li, Tong Zhao, Xinghao Zhu, Jiuguang Wang, Tao Pang, Kuan Fang <br>
                    Under review <br>
                    <a href="https://glide-manip.github.io/">Webpage</a>
                    &nbsp;&bull;&nbsp;
                    <a href="https://arxiv.org/abs/2412.02676">Paper</a>
                  </p>
                </div>

                <div class="research-proj">
                  <a href="https://yuffish.github.io/rebot/" class="research-thumb"><img src="images/projects/rebot.png" alt="" /></a>
                  <a href="https://yuffish.github.io/rebot/" class="research-proj-title">ReBot: Scaling Robot Learning with Real-to-Sim-to-Real Robotic Video Synthesis</a>
                  <p>
                    Yu Fang, Yue Yang, Xinghao Zhu, Kaiyuan Zheng, Gedas Bertasius, Daniel Szafir, Mingyu Ding <br>
                    IROS 2025 <br>
                    <a href="https://yuffish.github.io/rebot/">Webpage</a>
                    &nbsp;&bull;&nbsp;
                    <a href="https://arxiv.org/abs/2503.14526">Paper</a>
                  </p>
                </div>

                <div class="research-proj">
                  <a href="https://sites.google.com/view/phygrasp" class="research-thumb"><img src="images/projects/phygrasp.png" alt="" /></a>
                  <a href="https://sites.google.com/view/phygrasp" class="research-proj-title">PhyGrasp: Generalizing Robotic Grasping with Physics-informed Large Multimodal Models</a>
                  <p>
                    Dingkun Guo, Yuqi Xiang, Shuqi Zhao, Xinghao Zhu, Masayoshi Tomizuka, Mingyu Ding, Wei Zhan <br>
                    IROS 2025
                    &nbsp;&bull;&nbsp;
                    <a href="https://sites.google.com/view/phygrasp">Webpage</a>
                    &nbsp;&bull;&nbsp;
                    <a href="https://arxiv.org/abs/2402.16836">Paper</a>
                  </p>
                </div>

                <!-- <div class="research-proj">
                  <a href="https://arxiv.org/abs/2503.11019" class="research-thumb"><img src="images/projects/rpg.png" alt="" /></a>
                  <a href="https://arxiv.org/abs/2503.11019" class="research-proj-title">Residual Policy Gradient: A Reward View of KL-regularized Objective</a>
                  <p>
                    Pengcheng Wang, Xinghao Zhu, Yuxin Chen, Chenfeng Xu, Masayoshi Tomizuka, Chenran Li <br>
                    Under review <br>
                    <a href="https://arxiv.org/abs/2503.11019">Paper</a>
                  </p>
                </div> -->

                <div class="research-proj">
                  <a href="https://arxiv.org/abs/2402.18897" class="research-thumb"><img src="images/projects/cimpc.png" alt="" /></a>
                  <a href="https://arxiv.org/abs/2402.18897" class="research-proj-title">Contact-Implicit Model Predictive Control for Dexterous In-hand Manipulation </a>
                  <p>
                    Yongpeng Jiang, Mingrui Yu, Xinghao Zhu, Masayoshi Tomizuka, Xiang Li <br>
                    IROS 2024 <br>
                    <a href="https://arxiv.org/abs/2402.18897">Paper</a>
                  </p>
                </div>

                <div class="research-proj">
                  <a href="https://arxiv.org/abs/2403.12676" class="research-thumb"><img src="images/projects/dex_hand_follow.png" alt="" /></a>
                  <a href="https://arxiv.org/abs/2403.12676" class="research-proj-title">In-Hand Following of Deformable Linear Objects using Dexterous Fingers with Tactile Sensing</a>
                  <p>
                    Mingrui Yu, Boyuan Liang, Xiang Zhang, Xinghao Zhu, Lingfeng Sun, Changhao Wang, Shiji Song, Xiang Li, Masayoshi Tomizuka <br>
                    IROS 2024 <br>
                    <a href="https://arxiv.org/abs/2403.12676">Paper</a>
                  </p>
                </div>

                <div class="research-proj">
                  <a href="https://robotics-transformer-x.github.io/" class="research-thumb"><img src="images/projects/rtx.gif" alt="" /></a>
                  <a href="https://robotics-transformer-x.github.io/" class="research-proj-title">Open X-Embodiment: Robotic Learning Datasets and RT-X Models</a>
                  <p>
                    Open X-Embodiment Collaboration <br>
                    ICRA 2024 &nbsp;&nbsp;&bull;&nbsp;&nbsp; <strong>Best Paper Award</strong> <br>
                    <a href="https://robotics-transformer-x.github.io/">Webpage</a>
                    &nbsp;&bull;&nbsp;
                    <a href="https://robotics-transformer-x.github.io/paper.pdf">Paper</a>
                    &nbsp;&bull;&nbsp;
                    <a href="https://console.cloud.google.com/storage/browser/gresearch/robotics/open_x_embodiment_and_rt_x_oss;tab=objects?prefix=&forceOnObjectsSortingFiltering=false&pli=1">Code</a>
                    &nbsp;&bull;&nbsp;
                    <a href="https://docs.google.com/spreadsheets/d/1rPBD77tk60AEIGZrGSODwyyzs5FgCU9Uz3h-3_t2A9g/edit#gid=0">Dataset</a>
                    &nbsp;&bull;&nbsp;
                    <a href="https://www.deepmind.com/blog/scaling-up-learning-across-many-different-robot-types">Blogpost</a>
                  </p>
              </div>

              <div class="research-proj">
                <a href="https://arxiv.org/abs/2312.10571" class="research-thumb"><img src="images/projects/assembly.gif" alt="" /></a>
                <a href="https://arxiv.org/abs/2312.10571" class="research-proj-title">Multi-level Reasoning for Robotic Assembly: From Sequence Inference to Contact Selection</a>
                <p>
                  Xinghao Zhu, Devesh K. Jha, Diego Romeres, Lingfeng Sun, Masayoshi Tomizuka, Anoop Cherian <br>
                  ICRA 2024 <br>
                  <a href="https://arxiv.org/abs/2312.10571">Paper</a>
                </p>
              </div>

              <div class="research-proj">
                <a href="https://openreview.net/forum?id=apEdj9baZx" class="research-thumb"><img src="images/projects/llm.png" alt="" /></a>
                <a href="https://openreview.net/forum?id=apEdj9baZx" class="research-proj-title">LLM-POP: Large Language Model for Partially Observable Task Planning</a>
                <p>
                  Lingfeng Sun, Devesh K. Jha, Chiori Hori, Siddarth Jain, Radu Corcodel, Xinghao Zhu, Masayoshi Tomizuka, Diego Romeres <br>
                  Instruction Workshop, NeurIPS 2023 &nbsp;&nbsp;&bull;&nbsp;&nbsp; <strong>Honorable Mention</strong> <br>
                  ICRA 2024 <br>
                  <a href="https://arxiv.org/abs/2312.06876"> Paper</a>
                </p>
              </div>

              <div class="research-proj">
                <a href="https://sites.google.com/view/human-oriented-robot-learning" class="research-thumb"><img src="images/projects/representation_learn.gif" alt="" /></a>
                <a href="https://sites.google.com/view/human-oriented-robot-learning" class="research-proj-title">Human-oriented Representation Learning for Robotic Manipulation</a>
                <p>
                  Mingxiao Huo, Mingyu Ding, Chenfeng Xu, Thomas Tian, Xinghao Zhu, Yao Mu, Lingfeng Sun, Masayoshi Tomizuka, Wei Zhan <br>
                  RSS 2024 <br>
                  <a href="https://sites.google.com/view/human-oriented-robot-learning">Webpage</a>
                  &nbsp;&bull;&nbsp;
                  <a href="https://sites.google.com/berkeley.edu/fanuc-manipulation/home">Dataset</a>
                  &nbsp;&bull;&nbsp;
                  <a href="https://arxiv.org/abs/2310.03023">Paper</a>
                </p>
              </div>

              <div class="research-proj">
                <a href="https://sites.google.com/view/diff-lfd" class="research-thumb"><img src="images/projects/difflfd.gif" alt="" /></a>
                <a href="https://sites.google.com/view/diff-lfd" class="research-proj-title">Diff-LfD: Contact-aware Model-based Learning from Visual Demonstration for Robotic Manipulation via Differentiable Physics-based Simulation and Rendering</a>
                <p>
                  Xinghao Zhu, Jinghan Ke, Zhixuan Xu, Zhixin Sun, Bizhe Bai, Jun Lv, Qingtao Liu, Yuwei Zeng, Qi Ye, Cewu Lu, Masayoshi Tomizuka, Lin Shao <br>
                  CoRL 2023 &nbsp;&nbsp;&bull;&nbsp;&nbsp; <strong>Oral Presentation</strong> <br>
                  <a href="https://sites.google.com/view/diff-lfd">Webpage</a>
                  &nbsp;&bull;&nbsp;
                  <a href="https://openreview.net/pdf?id=DYPOvNot5F">Paper</a>
                </p>
            </div>

            <div class="research-proj">
              <a href="https://sites.google.com/view/admitlearn" class="research-thumb"><img src="images/projects/admitlearn.gif" alt="" /></a>
              <a href="https://sites.google.com/view/admitlearn" class="research-proj-title">Efficient Sim-to-real Transfer of Contact-Rich Manipulation Skills with Online Admittance Residual Learning</a>
              <p>
                Xiang Zhang, Changhao Wang, Lingfeng Sun, Zheng Wu, Xinghao Zhu, Masayoshi Tomizuka <br>
                CoRL 2023 <br>
                <a href="https://sites.google.com/view/admitlearn">Webpage</a>
                &nbsp;&bull;&nbsp;
                <a href="https://openreview.net/pdf?id=gFXVysXh48K">Paper</a>
              </p>
          </div>

              <div class="research-proj">
                <a href="index.html" class="research-thumb"><img src="images/projects/soft_griper.png" alt="" /></a>
                <a href="index.html" class="research-proj-title">Control of Soft Pneumatic Actuators with Approximated Dynamical Modeling</a>
                <p>
                  Wu-Te Yang, Burak KÃ¼rkÃ§Ã¼, Motohiro Hirao, Lingfeng Sun, Xinghao Zhu, Zhizhou Zhang, Grace X. Gu, Masayoshi Tomizuka <br>
                  ROBIO 2023 <br>
                  <a href="https://arxiv.org/abs/2310.01740">Paper</a>
                </p>
              </div>

              <div class="research-proj">
                <a href="https://www.youtube.com/watch?v=4nm05udhLzg" class="research-thumb"><img src="images/projects/allowcontact.gif" alt="" /></a>
                <a href="https://www.youtube.com/watch?v=4nm05udhLzg" class="research-proj-title">Allowing Safe Contact in Robotic Goal-Reaching: Planning and Tracking in Operational and Null Spaces</a>
                <p>
                  Xinghao Zhu, Wenzhao Lian, Bodi Yuan, C. Daniel Freeman, Masayoshi Tomizuka <br>
                  ICRA 2023 <br>
                  <a href="https://www.youtube.com/watch?v=4nm05udhLzg">Video</a>
                  &nbsp;&bull;&nbsp;
                  <a href="https://github.com/RolandZhu/ContactGoalReach">Code</a>
                  &nbsp;&bull;&nbsp;
                  <a href="https://ieeexplore.ieee.org/document/10160649">Paper</a>
                </p>
              </div>

              <div class="research-proj">
                <a href="https://www.youtube.com/watch?v=vHTMWdj4n7o" class="research-thumb"><img src="images/projects/mlgsl.gif" alt="" /></a>
                <a href="https://www.youtube.com/watch?v=vHTMWdj4n7o" class="research-proj-title">Learn to Grasp with Less Supervision: A Data-Efficient Maximum Likelihood Grasp Sampling Loss</a>
                <p>
                  Xinghao Zhu, Yefan Zhou, Yongxiang Fan, Lingfeng Sun, Jianyu Chen, Masayoshi Tomizuka <br>
                  ICRA 2022 <br>
                  <a href="https://www.youtube.com/watch?v=vHTMWdj4n7o">Video</a>
                  &nbsp;&bull;&nbsp;
                  <a href="https://ieeexplore.ieee.org/document/9811685">Paper</a>
                </p>
              </div>

              <div class="research-proj">
                <a href="https://ieeexplore.ieee.org/document/9812092" class="research-thumb"><img src="images/projects/tactile_sim.gif" alt="" /></a>
                <a href="https://ieeexplore.ieee.org/document/9812092" class="research-proj-title">Learning to Synthesize Volumetric Meshes from Vision-based Tactile Imprints</a>
                <p>
                  Xinghao Zhu, Siddarth Jain, Masayoshi Tomizuka, Jeroen Van Baar <br>
                  ICRA 2022 <br>
                  <a href="https://ieeexplore.ieee.org/document/9812092">Paper</a>
                </p>
              </div>

              <div class="research-proj">
                <a href="https://ieeexplore.ieee.org/document/9867454" class="research-thumb"><img src="images/projects/bpomp.png" alt="" /></a>
                <a href="https://ieeexplore.ieee.org/document/9867454" class="research-proj-title">BPOMP: A Bilevel Path Optimization Formulation for Motion Planning</a>
                <p>
                  Changhao Wang, Hsien-Chung Lin, Shiyu Jin, Xinghao Zhu, Liting Sun, Masayoshi Tomizuka <br>
                  American Control Conference (ACC) 2022 <br>
                  <a href="https://changhaowang.github.io/BPOMP/BPOMP.html">Webpage</a>
                  &nbsp;&bull;&nbsp;
                  <a href="https://ieeexplore.ieee.org/document/9867454">Paper</a>
                </p>
              </div>

              <div class="research-proj">
                <a href="https://ieeexplore.ieee.org/document/9811973" class="research-thumb"><img src="images/projects/insert_prim.png" alt="" /></a>
                <a href="https://ieeexplore.ieee.org/document/9811973" class="research-proj-title">Learning Insertion Primitives with Hybrid Action Space for Robotic Assembly Tasks</a>
                <p>
                  Xiang Zhang, Shiyu Jin, Changhao Wang, Xinghao Zhu, Masayoshi Tomizuka <br>
                  ICRA 2022 <br>
                  <a href="https://msc.berkeley.edu/research/insertion-primitives.html">Webpage</a>
                  &nbsp;&bull;&nbsp;
                  <a href="https://ieeexplore.ieee.org/document/9811973">Paper</a>
                </p>
              </div>

              <div class="research-proj">
                <a href="https://ieeexplore.ieee.org/document/9732674" class="research-thumb"><img src="images/projects/hybrid_cable.png" alt="" /></a>
                <a href="https://ieeexplore.ieee.org/document/9732674" class="research-proj-title">Offline-Online Learning of Deformation Model for Cable Manipulation With Graph Networks</a>
                <p>
                  Changhao Wang, Yuyou Zhang, Xiang Zhang, Zheng Wu, Xinghao Zhu, Shiyu Jin, Te Tang, Masayoshi Tomizuka <br>
                  RAL 2022 <br>
                  <a href="https://ieeexplore.ieee.org/document/9732674">Paper</a>
                </p>
              </div>

              <div class="research-proj">
                <a href="https://www.youtube.com/watch?v=rXldZyf6Kks" class="research-thumb"><img src="images/projects/cgpn.gif" alt="" /></a>
                <a href="https://www.youtube.com/watch?v=rXldZyf6Kks" class="research-proj-title">6-DoF Contrastive Grasp Proposal Network</a>
                <p>
                  Xinghao Zhu, Lingfeng Sun, Yongxiang Fan, Masayoshi Tomizuka <br>
                  ICRA 2021 <br>
                  <a href="https://www.youtube.com/watch?v=rXldZyf6Kks">Video</a>
                  &nbsp;&bull;&nbsp;
                  <a href="https://ieeexplore.ieee.org/document/9561954">Paper</a>
                </p>
              </div>
              
              <div class="research-proj">
                <a href="https://ieeexplore.ieee.org/document/9482981" class="research-thumb"><img src="images/projects/contact_pose_id.png" alt="" /></a>
                <a href="https://ieeexplore.ieee.org/document/9482981" class="research-proj-title">Contact Pose Identification for Peg-in-Hole Assembly Under Uncertainties</a>
                <p>
                  Shiyu Jin, Xinghao Zhu, Changhao Wang, Masayoshi Tomizuka <br>
                  ACC 2021 <br>
                  <a href="https://ieeexplore.ieee.org/document/9482981">Paper</a>
                </p>
              </div>

              <div class="research-proj">
                <a href="https://ieeexplore.ieee.org/document/8967560" class="research-thumb"><img src="images/projects/ppojpo.gif" alt="" /></a>
                <a href="https://ieeexplore.ieee.org/document/8967560" class="research-proj-title">Optimization Model for Planning Precision Grasps with Multi-Fingered Hands</a>
                <p>
                  Yongxiang Fan, Xinghao Zhu, Masayoshi Tomizuka <br>
                  IROS 2019 <br>
                  <a href="https://yongxf.github.io/IROS2019/ppojpo.html">Webpage</a>
                  &nbsp;&bull;&nbsp;
                  <a href="https://ieeexplore.ieee.org/document/8967560">Paper</a>
                </p>
              </div>

              <div style="clear: both;"></div>
            </div>

            <!-------------------------------------------------------------------------->
            <!----------------------------Reviewer-------------------------------------->
            <!-------------------------------------------------------------------------->
            <div class="divider"></div>
            <div class="section">
                <h1>Academic Service</h1>
                <p>
                    <ul>
                      <li> Conference Reviewer for RSS, CoRL, ICRA, IROS, ROBIO, ICLR </li>
                      <li> Journal Reviewer for TRO, RA-L, TCDS </li>
                      <li> Associate Editor for IROS 2025 </li>

                    </ul>
                </p>
                <div style="clear: both;"></div>
            </div>

            <!-------------------------------------------------------------------------->
            <!----------------------------Teaching-------------------------------------->
            <!-------------------------------------------------------------------------->
            <div class="divider"></div>
            <div class="section">
                <h1>Teaching</h1>
                <p>
                    <ul>
                      <li> Graduate Student Instructor, ME 233 Advanced Control Systems II, UC Berkeley, Spring 2024 </li>

                    </ul>
                </p>
                <div style="clear: both;"></div>
            </div>

            <!-------------------------------------------------------------------------->
            <!--------------------------Collaborator------------------------------------>
            <!-------------------------------------------------------------------------->
            <!-- <div class="divider"></div>
            <div class="section sponsors">
                <h1>Collaborators</h1>
                <div class="sponsor-thumb">
                  <a href="https://www.fanucamerica.com/"><img src="./images/collaborators/fanuc_logo.png" alt="" /></a>
                  <a href="https://x.company/"><img src="./images/collaborators/x_logo.png" alt="" /></a>
                  <a href="https://www.tri.global/"><img src="./images/collaborators/tri_logo.png" alt="" /></a>
                  <a href="https://www.merl.com/"><img src="./images/collaborators/merl_logo.png" alt="" /></a>  
                </div>
                <div style="clear: both;"></div>
            </div> -->
        </div>

        <script>
            function toggleNews() {
              var moreNews = document.getElementById("moreNews");
              var moreNewsBtn = document.getElementById("moreNewsBtn");
              var lessNewsBtn = document.getElementById("lessNewsBtn");
              if (moreNewsBtn.style.display === "none") {
                moreNews.style.display = "none";
                moreNewsBtn.style.display = "inline";
                lessNewsBtn.style.display = "none";
              } else {
                moreNews.style.display = "inline";
                moreNewsBtn.style.display = "none";
                lessNewsBtn.style.display = "inline";
              }
            }


            function toggleTalks() {
              var moreTalks = document.getElementById("moreTalks");
              var moreTalksBtn = document.getElementById("moreTalksBtn");
              var lessTalksBtn = document.getElementById("lessTalksBtn");
              
              if (moreTalksBtn.style.display === "none") {
                moreTalks.style.display = "none";
                moreTalksBtn.style.display = "inline";
                lessTalksBtn.style.display = "none";
              } else {
                moreTalks.style.display = "inline";
                moreTalksBtn.style.display = "none";
                lessTalksBtn.style.display = "inline";
              }
            }
            function togglePubs() {
              var morePubs = document.getElementById("morePubs");
              var morePubsBtn = document.getElementById("morePubsBtn");
              var lessPubsBtn = document.getElementById("lessPubsBtn");
              if (morePubsBtn.style.display === "none") {
                morePubs.style.display = "none";
                morePubsBtn.style.display = "inline";
                lessPubsBtn.style.display = "none";
              } else {
                morePubs.style.display = "inline";
                morePubsBtn.style.display = "none";
                lessPubsBtn.style.display = "inline";
              }
            }

            function showRep() {
              var repBtn = document.getElementById("repBtn");
              var showAllBtn = document.getElementById("showAllBtn");
              repBtn.style.color = "#49bf9d";
              repBtn.style.borderBottom = "1px solid #a4dfce";
              showAllBtn.style.color = "#191e3f";
              showAllBtn.style.borderBottom = "none";
              var  = document.getElementsByClassName("");
              for (var i = 0; i < .length; i++) {
                .item(i).style.display = "none";
              }
            }

            function hideRep() {
              var repBtn = document.getElementById("repBtn");
              var showAllBtn = document.getElementById("showAllBtn");
              repBtn.style.color = "#191e3f";
              repBtn.style.borderBottom = "none";
              showAllBtn.style.color = "#49bf9d";
              showAllBtn.style.borderBottom = "1px solid #a4dfce";
              var  = document.getElementsByClassName("");
              for (var i = 0; i < .length; i++) {
                .item(i).style.display = "table";
              }
            }
        </script>
    </body>
</html>